{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# llm\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "\n",
    "chat_template = \"\"\"\n",
    "나는 사용자의 직업을 추천해주는 챗봇이다. \n",
    "\n",
    "1. 이력서를 기반으로 저장된 이력서 파일과 유사도를 파악한다. \n",
    "2. 파악한 유사도를 기반으로 직업을 3가지 추천해준다. \n",
    "3. 이때 추천 직업별로 유사도 퍼센트를 포함하여 제공한다.\n",
    "4. 직업추천 순서는 유사도가 높은 순서대로 제공한다. \n",
    "\"\"\"\n",
    "\n",
    "chat_ai = ChatOpenAI(temperature=0.5, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval QA Chain 생성\n",
    "loader = CSVLoader(\"../../data/rallit_text.csv\", encoding='utf8')\n",
    "data = loader.load()\n",
    "\n",
    "# Split the text in chunks, using LangChain Recursive Character Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    "    )\n",
    "\n",
    "pages = loader.load_and_split(text_splitter)\n",
    "\n",
    "# Create a persistent, file-based vector store, using Chroma vector store.\n",
    "directory = 'data'\n",
    "vector_index = Chroma.from_documents(\n",
    "    pages, # Documents\n",
    "    OpenAIEmbeddings(), # Text embedding model\n",
    "    persist_directory=directory # persists the vectors to the file system\n",
    "    )\n",
    "\n",
    "vector_index.persist()\n",
    "\n",
    "# Create the retriever and the query-interface.\n",
    "retriever = vector_index.as_retriever(\n",
    "    search_type=\"similarity\", # Cosine Similarity\n",
    "    search_kwargs={\n",
    "        \"k\": 3, # Select top k search results\n",
    "    }\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True # source document which were used as source files\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 705\n",
      "============================================================\n",
      "[HUMAN]\n",
      "기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\n",
      "\n",
      "[AI]\n",
      "풀스택 개발자\n"
     ]
    }
   ],
   "source": [
    "# Retrieval QA Chain 생성\n",
    "loader = CSVLoader(\"../../data/rallit_text.csv\", encoding='utf8')\n",
    "docs = loader.load()\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# 단계 4: 검색(Search)\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 단계 5: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "'''\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. You recommend a user's job.\n",
    "\n",
    "1. 이력서를 기반으로 저장된 이력서 파일과 유사도를 파악한다. \n",
    "2. 파악한 유사도를 기반으로 직업을 3가지 추천해준다. \n",
    "3. 이때 추천 직업별로 유사도 퍼센트를 포함하여 제공한다.\n",
    "4. 직업추천 순서는 유사도가 높은 순서대로 제공한다. \n",
    "\n",
    "Context: {context}\n",
    "Question: {question} \n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=template\n",
    ")\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# 단계 6: 언어모델 생성(Create LLM)\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 단계 7: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\"\n",
    "#question = \"기술스택: python, sql, matplotlib, seaborn, selenium ,프로젝트: 카드사 고객 이탈 데이터 분석을 통한 아이디어 발굴 프로젝트. 크롤링을 통한 데이터 수집과 데이터 시각화, 예측 모델 설계를 담당했습니다. 추천 직업을 알려주세요\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"문서의 수: {len(data)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4361, which is longer than the specified 1000\n",
      "Created a chunk of size 1108, which is longer than the specified 1000\n",
      "Created a chunk of size 2631, which is longer than the specified 1000\n",
      "Created a chunk of size 1232, which is longer than the specified 1000\n",
      "Created a chunk of size 1288, which is longer than the specified 1000\n",
      "Created a chunk of size 1003, which is longer than the specified 1000\n",
      "Created a chunk of size 1017, which is longer than the specified 1000\n",
      "Created a chunk of size 1179, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='백엔드 개발자' response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 1180, 'total_tokens': 1189}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-81f60129-2da3-49a7-89c2-6b4f86924e23-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/practice/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "folder_path = \"../../data/job/\"\n",
    "file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = CSVLoader(file_path, encoding='utf8')\n",
    "    docs.extend(loader.load_and_split(text_splitter=splitter))\n",
    "\n",
    "\n",
    "#loader = CSVLoader(\"../../data/\", encoding='utf8')\n",
    "#docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a helpful job recommendation assistant. \n",
    "            Answer the question based on the context below. You recommend a user's job. And just print the job name. Don't print dupliacted job.\n",
    "            You provide the order of the job recommendations in the order of the highest similarity. \n",
    "\n",
    "            1. Determines the similarity of user's resume to a saved resume file. \n",
    "            2. It recommends 3 jobs based on the similarity. \n",
    "\n",
    "            \\n\\n\n",
    "            {context}\",\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='백엔드 개발자' response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 1689, 'total_tokens': 1698}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_a450710239', 'finish_reason': 'stop', 'logprobs': None} id='run-a74b1a1e-df64-4e60-91d4-a9b8e8a56a9e-0'\n"
     ]
    }
   ],
   "source": [
    "# MMR - 다양성 고려 (lambda_mult = 0.5)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 5, 'fetch_k': 50}\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='풀스택 개발자' response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 1636, 'total_tokens': 1646}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-517b78f3-2fbc-473a-aa01-0d043f8bd6ac-0'\n"
     ]
    }
   ],
   "source": [
    "# Similarity score threshold (기준 스코어 이상인 문서를 대상으로 추출)\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='similarity_score_threshold',\n",
    "    search_kwargs={'score_threshold': 0.3}\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='풀스택 개발자' response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 1636, 'total_tokens': 1646}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-3f3644ea-a8ef-4f47-8e95-8efc3f4d67d6-0'\n"
     ]
    }
   ],
   "source": [
    "#Refine\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.', 'result': '백엔드 개발자', 'source_documents': [Document(page_content='job: 풀스택 개발자\\ntext: 기술 스택: Node.js\\r\\nJava\\r\\nJavaScript\\r\\nPython\\r\\nReact\\r\\nExpress\\r\\nPostgreSQL\\r\\nMySQL\\r\\nDjango\\r\\nKotlin\\r\\nAndroid\\r\\nGit\\r\\nGithub\\r\\n프로젝트 관리\\r\\nHTML/CSS, 경력: 대진기술정보(주), 연구소장 ? 공간정보연구소, 외주를 통해 S/W 사업을 진행하던 회사에 신규 개발자(연구원)로 커리어를 시작하였으며, 현재까지 독학으로 개발 능력을 키워가며 웹 및 모바일 어플리케이션 개발을 전담하고 있습니다.\\r\\n기존에 납품하던 로컬 CS 상하수도 관리시스템에 결합할 웹조회시스템을 풀스택으로 개발하고, 유지관리도 담당하고 있습니다. 해당 시스템은 현재 다수의 경북 권내 상하수도 관리기관에 납품되어 있으며, 일선 공무원들이 업무에 가장 많이 활용하는 시스템 중 하나입니다.', metadata={'source': '../../data/rallit_text.csv', 'row': 40}), Document(page_content='job: 백엔드 개발자\\ntext: 기술 스택: Python, Django, Java, Spring, Spring Boot, MySQL, PostgreSQL, Docker, AWS, 경력: (사)스마트인재개발원, 연구원 | 기획팀 | 퇴사, 2020.09. ~ 2022.12. (2년 4개월), 주 업무 : Python / Machine Learning 강의\\r\\n부 업무 : 담임업무 / 강의 스케줄 기획 및 관리, 프로젝트: 주가 이야기, 개인, 2024.02. ~ 2024.03., 종목 주가지표를 보여주고 사용자간 종목에 관한 커뮤니티 기능을 이용할 수 있는 프로젝트\\r\\n\\r\\n주요 경험\\r\\n\\r\\n종목 4469개 5년치 주가지표데이터 DB INSERT 성능 개선\\r\\nDB INSERT 시간 ( 50m 35s 227ms ) 성능개선 시도\\r\\nBatchUpdate를 사용하여 시간개선 ( 6m 22s 487ms )\\r\\n멀티스레드를 사용하여 시간개선 ( 3m 50s 997 ms )\\r\\n\\r\\n스프링 배치 프로세스 운영 효율 개선\\r\\n주가 일봉 데이터를 업데이트 하기 위해 스프링 배치를 활용하여 작업을 일별로 스케줄링 처리 하였으나 서버를 지속적으로 가동해야하는 비효율적인 상황 발생\\r\\n젠킨스를 활용한 작업 관리자를 구성하여 정해진 시간에만 스프링 배치 프로세스가 실행되게 개선하여 자원 활용 및 운영 효율을 개선', metadata={'source': '../../data/rallit_text.csv', 'row': 692}), Document(page_content='job: 백엔드 개발자\\ntext: 기술 스택: Java, Spring, Spring Boot, MySQL, Python, JPA', metadata={'source': '../../data/rallit_text.csv', 'row': 494}), Document(page_content='job: 백엔드 개발자\\ntext: 기술 스택: Java, Spring, Spring Boot, Node.js, 경력: 연합시스템, 현장실습생 | IT 개발부 | 퇴사, 2021.09. ~ 2023.01. (1년 5개월), 졸업했던 고등학교에선 운영하던 도제학교라는 프로그램에 참여하여, 한 회사에 현장실습생 신분으로 1주에 2일씩 1.5년 동안 다녔습니다.\\r\\n고등학생이 절대로 경험할 수 없고, 접할 수 없는 현업에서의 얘기와 실무의 대해서 부서 내에 개발자분들 덕분에 한층 더 배워나갔습니다.\\r\\n\\r\\n파이썬으로 자료구조, 알고리즘 강의를 통해 학습함.\\r\\n\\r\\n회사의 GCP Mysql에 연결하여 사내 공작기계 lot 번호를 입력 시 공정 종료 시간을 계산하고, 결과값을 정렬하여 출력하는 Python 프로그램을 친구와 함께 개발함.\\r\\n\\r\\nMySQL WorkBench를 사용하여 실시간 데이터를 검색하고 비정상적인 데이터를 식별하여 정상화하는 데 기여함.\\r\\n\\r\\n남은 시간들은 자습을 했고, 자바와 스프링 부트를 중점으로 학습함.', metadata={'source': '../../data/rallit_text.csv', 'row': 262})]}\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "            You are a helpful assistant. \n",
    "            Answer the question based on the context below. You recommend a user's job. And just print the job name. Don't print dupliacted job.\n",
    "            You provide the order of the job recommendations in the order of the highest similarity. \n",
    "\n",
    "            1. Determines the similarity of user's resume to a saved resume file. \n",
    "            2. It recommends 3 jobs based on the similarity. \n",
    "\n",
    "            \\n\n",
    "            {context}\n",
    "            Question: {question}\n",
    "            Answer: \"\"\"\n",
    "\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever = vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "question = \"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\"\n",
    "result = qa_chain({\"query\": question})\n",
    "# Check the result of the query\n",
    "result[\"result\"]\n",
    "# Check the source document from where we \n",
    "#result[\"source_documents\"][0]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주어진 정보에 따라서 사용자에게 추천할 수 있는 직업은 데이터 엔지니어, 백엔드 개발자, 시스템 개발자, 또는 소프트웨어 엔지니어와 같은 직업이 적합할 수 있습니다. 또한, Kubernetes에 대한 지식이 있는 경우 클라우드 엔지니어나 데브옵스 엔지니어로도 진출할 수 있습니다. 이러한 직업들은 주어진 기술 스택과 경험을 활용하여 성장할 수 있는 분야일 수 있습니다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type=\"map_reduce\",\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주어진 추가 정보를 바탕으로, 백엔드 개발자로서 Java, Spring, Spring Boot, Node.js와 같은 기술을 사용하여 연합시스템에서 현장실습생으로 일한 경력이 있습니다. 또한, 고등학교에서 도제학교 프로그램에 참여하면서 현업에서의 경험을 쌓았고, 파이썬을 활용하여 자료구조, 알고리즘을 학습하고 GCP MySQL과 연동하여 프로그램을 개발한 경험이 있습니다. MySQL WorkBench를 사용하여 데이터를 검색하고 정상화하는 데 기여한 경험도 있습니다. 이러한 경험을 바탕으로 데이터 엔지니어 또는 백엔드 개발자로서의 경력을 고려할 수 있습니다.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyeon\\isic\\2024-1-DSCD-ISIC-1\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:367: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.', 'result': '백엔드 개발자'}\n"
     ]
    }
   ],
   "source": [
    "#Map re-rank\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    #prompt=prompt,\n",
    "    chain_type=\"map_rerank\",\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading ['../../data/job/output_data_anlysis.csv', '../../data/job/output_data_engineer.csv', '../../data/job/output_devops.csv', '../../data/job/output_pm.csv', '../../data/job/rallit_text.csv']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hyeon\\isic\\2024-1-DSCD-ISIC-1\\venv\\Lib\\site-packages\\langchain_community\\document_loaders\\csv_loader.py:67\u001b[0m, in \u001b[0;36mCSVLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__read_file(csvfile)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     34\u001b[0m loader \u001b[38;5;241m=\u001b[39m CSVLoader(file_paths, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_splitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 벡터 저장소 생성\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hyeon\\isic\\2024-1-DSCD-ISIC-1\\venv\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:63\u001b[0m, in \u001b[0;36mBaseLoader.load_and_split\u001b[1;34m(self, text_splitter)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     _text_splitter \u001b[38;5;241m=\u001b[39m text_splitter\n\u001b[1;32m---> 63\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(docs)\n",
      "File \u001b[1;32mc:\\Users\\hyeon\\isic\\2024-1-DSCD-ISIC-1\\venv\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:29\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_load())\n",
      "File \u001b[1;32mc:\\Users\\hyeon\\isic\\2024-1-DSCD-ISIC-1\\venv\\Lib\\site-packages\\langchain_community\\document_loaders\\csv_loader.py:84\u001b[0m, in \u001b[0;36mCSVLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error loading ['../../data/job/output_data_anlysis.csv', '../../data/job/output_data_engineer.csv', '../../data/job/output_devops.csv', '../../data/job/output_pm.csv', '../../data/job/rallit_text.csv']"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# 환경 변수를 로드하고 API 키를 설정합니다.\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 언어 모델 초기화\n",
    "#llm = ChatOpenAI(temperature=0)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "\n",
    "# 텍스트 분할 설정\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    #separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# 문서 로드 및 분할\n",
    "folder_path = \"../../data/job/\"\n",
    "file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "loader = CSVLoader(file_paths, encoding='utf8')\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# 벡터 저장소 생성\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 검색기 설정\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a helpful job recommendation assistant. \n",
    "            Answer the question based on the context below. You recommend a user's job. And just print the job name. Don't print duplicated jobs.\n",
    "            You provide the order of the job recommendations in the order of the highest similarity. \n",
    "\n",
    "            1. Determines the similarity of the user's resume to a saved resume file. \n",
    "            2. It recommends up to 3 jobs based on the similarity. \n",
    "\n",
    "            \\n\\n\n",
    "            {context}\",\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 실행 체인 정의 및 결과 출력\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\":RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='풀스택 개발자\\n백엔드 개발자' response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 2075, 'total_tokens': 2095}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-cccf5280-0341-47f3-89c6-fc08dc7176dd-0'\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# 환경 변수를 로드하고 API 키를 설정합니다.\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 언어 모델 초기화\n",
    "#llm = ChatOpenAI(temperature=0)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "# 캐시 디렉토리 설정\n",
    "cache_dir = LocalFileStore(\"./.cache/practice/\")\n",
    "\n",
    "# 텍스트 분할 설정\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    #separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# 문서 로드 및 분할\n",
    "folder_path = \"../../data/job/\"\n",
    "file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Map 함수: 각 파일을 로드하고 분할하여 문서 리스트를 반환합니다.\n",
    "def load_and_split(file_path):\n",
    "    loader = CSVLoader(file_path, encoding='utf8')\n",
    "    return loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# Reduce 함수: 여러 문서 리스트를 하나의 리스트로 결합합니다.\n",
    "def combine_docs(accumulated_docs, docs):\n",
    "    accumulated_docs.extend(docs)\n",
    "    return accumulated_docs\n",
    "\n",
    "# MapReduce 적용: 문서 로드 및 분할, 문서 결합\n",
    "mapped_docs = map(load_and_split, file_paths)\n",
    "docs = reduce(combine_docs, mapped_docs, [])\n",
    "\n",
    "# 임베딩과 캐싱 설정\n",
    "embeddings = OpenAIEmbeddings()\n",
    "#cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 검색기 설정\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a helpful job recommendation assistant. \n",
    "            Answer the question based on the context below. You recommend a user's job. And just print the job name. Don't print duplicated jobs.\n",
    "            You provide the order of the job recommendations in the order of the highest similarity. \n",
    "\n",
    "            1. Determines the similarity of the user's resume to a saved resume file. \n",
    "            2. It recommends up to 3 jobs based on the similarity. \n",
    "\n",
    "            \\n\\n\n",
    "            {context}\",\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 실행 체인 정의 및 결과 출력\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\":RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
