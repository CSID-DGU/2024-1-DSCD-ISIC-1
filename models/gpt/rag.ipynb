{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyeon\\isic\\2024-1-DSCD-ISIC-1\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# llm\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "\n",
    "chat_template = \"\"\"\n",
    "나는 사용자의 직업을 추천해주는 챗봇이다. \n",
    "\n",
    "1. 이력서를 기반으로 저장된 이력서 파일과 유사도를 파악한다. \n",
    "2. 파악한 유사도를 기반으로 직업을 3가지 추천해준다. \n",
    "3. 이때 추천 직업별로 유사도 퍼센트를 포함하여 제공한다.\n",
    "4. 직업추천 순서는 유사도가 높은 순서대로 제공한다. \n",
    "\"\"\"\n",
    "\n",
    "chat_ai = ChatOpenAI(temperature=0.5, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyeon\\isic\\2024-1-DSCD-ISIC-1\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\hyeon\\isic\\2024-1-DSCD-ISIC-1\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Retrieval QA Chain 생성\n",
    "loader = CSVLoader(\"../../data/rallit_text.csv\", encoding='utf8')\n",
    "data = loader.load()\n",
    "\n",
    "# Split the text in chunks, using LangChain Recursive Character Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    "    )\n",
    "\n",
    "pages = loader.load_and_split(text_splitter)\n",
    "\n",
    "# Create a persistent, file-based vector store, using Chroma vector store.\n",
    "directory = 'data'\n",
    "vector_index = Chroma.from_documents(\n",
    "    pages, # Documents\n",
    "    OpenAIEmbeddings(), # Text embedding model\n",
    "    persist_directory=directory # persists the vectors to the file system\n",
    "    )\n",
    "\n",
    "vector_index.persist()\n",
    "\n",
    "# Create the retriever and the query-interface.\n",
    "retriever = vector_index.as_retriever(\n",
    "    search_type=\"similarity\", # Cosine Similarity\n",
    "    search_kwargs={\n",
    "        \"k\": 3, # Select top k search results\n",
    "    }\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True # source document which were used as source files\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'skill: python, java, kubernates, 프로젝트: 학교 웹사이트 개발에서 백엔드 담당, 데이터베이스 구축, 교육: 컴퓨터공학과.',\n",
       " 'result': 'The user seems to be providing information rather than asking a question. However, if the user is asking if these skills and experiences are suitable for the job of a backend developer, then yes, the skills of Python, Java, and Kubernetes are relevant. Experience in project work such as backend responsibility in school website development and database construction is also valuable. Having an education in computer science is also beneficial for a backend developer role.',\n",
       " 'source_documents': [Document(page_content='job: 백엔드 개발자\\ntext: 기술 스택: Java, Spring, Spring Boot, MySQL, Python, JPA', metadata={'row': 494, 'source': '../../data/rallit_text.csv'}),\n",
       "  Document(page_content='job: 백엔드 개발자\\ntext: 기술 스택: Java, Spring, Spring Boot, MySQL, Python, JPA', metadata={'row': 494, 'source': '../../data/rallit_text.csv'}),\n",
       "  Document(page_content='job: 백엔드 개발자\\ntext: 기술 스택: Python, Django, GitHub, Git, AWS, Linux, ubuntu, C, 교육: 경북대학교, 대학교(학사) | 소프트웨어학과, 2017.03. ~ 현재 | 재학 중, 자격증: SQLD, 한국데이터산업진흥원, 2023.12., 외국어: 영어, 일상 회화 가능', metadata={'row': 340, 'source': '../../data/rallit_text.csv'})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke(\"skill: python, java, kubernates, 프로젝트: 학교 웹사이트 개발에서 백엔드 담당, 데이터베이스 구축, 교육: 컴퓨터공학과.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 705\n",
      "============================================================\n",
      "[HUMAN]\n",
      "기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\n",
      "\n",
      "[AI]\n",
      "풀스택 개발자\n"
     ]
    }
   ],
   "source": [
    "# Retrieval QA Chain 생성\n",
    "loader = CSVLoader(\"../../data/rallit_text.csv\", encoding='utf8')\n",
    "docs = loader.load()\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# 단계 4: 검색(Search)\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 단계 5: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "'''\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. You recommend a user's job.\n",
    "\n",
    "1. 이력서를 기반으로 저장된 이력서 파일과 유사도를 파악한다. \n",
    "2. 파악한 유사도를 기반으로 직업을 3가지 추천해준다. \n",
    "3. 이때 추천 직업별로 유사도 퍼센트를 포함하여 제공한다.\n",
    "4. 직업추천 순서는 유사도가 높은 순서대로 제공한다. \n",
    "\n",
    "Context: {context}\n",
    "Question: {question} \n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=template\n",
    ")\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# 단계 6: 언어모델 생성(Create LLM)\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 단계 7: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\"\n",
    "#question = \"기술스택: python, sql, matplotlib, seaborn, selenium ,프로젝트: 카드사 고객 이탈 데이터 분석을 통한 아이디어 발굴 프로젝트. 크롤링을 통한 데이터 수집과 데이터 시각화, 예측 모델 설계를 담당했습니다. 추천 직업을 알려주세요\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"문서의 수: {len(data)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 688, which is longer than the specified 600\n",
      "Created a chunk of size 635, which is longer than the specified 600\n",
      "Created a chunk of size 689, which is longer than the specified 600\n",
      "Created a chunk of size 792, which is longer than the specified 600\n",
      "Created a chunk of size 652, which is longer than the specified 600\n",
      "Created a chunk of size 636, which is longer than the specified 600\n",
      "Created a chunk of size 674, which is longer than the specified 600\n",
      "Created a chunk of size 726, which is longer than the specified 600\n",
      "Created a chunk of size 646, which is longer than the specified 600\n",
      "Created a chunk of size 920, which is longer than the specified 600\n",
      "Created a chunk of size 652, which is longer than the specified 600\n",
      "Created a chunk of size 4361, which is longer than the specified 600\n",
      "Created a chunk of size 1000, which is longer than the specified 600\n",
      "Created a chunk of size 645, which is longer than the specified 600\n",
      "Created a chunk of size 845, which is longer than the specified 600\n",
      "Created a chunk of size 743, which is longer than the specified 600\n",
      "Created a chunk of size 800, which is longer than the specified 600\n",
      "Created a chunk of size 841, which is longer than the specified 600\n",
      "Created a chunk of size 748, which is longer than the specified 600\n",
      "Created a chunk of size 708, which is longer than the specified 600\n",
      "Created a chunk of size 854, which is longer than the specified 600\n",
      "Created a chunk of size 925, which is longer than the specified 600\n",
      "Created a chunk of size 691, which is longer than the specified 600\n",
      "Created a chunk of size 624, which is longer than the specified 600\n",
      "Created a chunk of size 659, which is longer than the specified 600\n",
      "Created a chunk of size 619, which is longer than the specified 600\n",
      "Created a chunk of size 987, which is longer than the specified 600\n",
      "Created a chunk of size 676, which is longer than the specified 600\n",
      "Created a chunk of size 987, which is longer than the specified 600\n",
      "Created a chunk of size 676, which is longer than the specified 600\n",
      "Created a chunk of size 760, which is longer than the specified 600\n",
      "Created a chunk of size 1108, which is longer than the specified 600\n",
      "Created a chunk of size 619, which is longer than the specified 600\n",
      "Created a chunk of size 666, which is longer than the specified 600\n",
      "Created a chunk of size 950, which is longer than the specified 600\n",
      "Created a chunk of size 2631, which is longer than the specified 600\n",
      "Created a chunk of size 671, which is longer than the specified 600\n",
      "Created a chunk of size 706, which is longer than the specified 600\n",
      "Created a chunk of size 1232, which is longer than the specified 600\n",
      "Created a chunk of size 639, which is longer than the specified 600\n",
      "Created a chunk of size 1288, which is longer than the specified 600\n",
      "Created a chunk of size 758, which is longer than the specified 600\n",
      "Created a chunk of size 612, which is longer than the specified 600\n",
      "Created a chunk of size 965, which is longer than the specified 600\n",
      "Created a chunk of size 1003, which is longer than the specified 600\n",
      "Created a chunk of size 717, which is longer than the specified 600\n",
      "Created a chunk of size 787, which is longer than the specified 600\n",
      "Created a chunk of size 658, which is longer than the specified 600\n",
      "Created a chunk of size 620, which is longer than the specified 600\n",
      "Created a chunk of size 827, which is longer than the specified 600\n",
      "Created a chunk of size 963, which is longer than the specified 600\n",
      "Created a chunk of size 601, which is longer than the specified 600\n",
      "Created a chunk of size 639, which is longer than the specified 600\n",
      "Created a chunk of size 608, which is longer than the specified 600\n",
      "Created a chunk of size 731, which is longer than the specified 600\n",
      "Created a chunk of size 612, which is longer than the specified 600\n",
      "Created a chunk of size 867, which is longer than the specified 600\n",
      "Created a chunk of size 905, which is longer than the specified 600\n",
      "Created a chunk of size 604, which is longer than the specified 600\n",
      "Created a chunk of size 699, which is longer than the specified 600\n",
      "Created a chunk of size 880, which is longer than the specified 600\n",
      "Created a chunk of size 986, which is longer than the specified 600\n",
      "Created a chunk of size 692, which is longer than the specified 600\n",
      "Created a chunk of size 847, which is longer than the specified 600\n",
      "Created a chunk of size 613, which is longer than the specified 600\n",
      "Created a chunk of size 641, which is longer than the specified 600\n",
      "Created a chunk of size 839, which is longer than the specified 600\n",
      "Created a chunk of size 660, which is longer than the specified 600\n",
      "Created a chunk of size 680, which is longer than the specified 600\n",
      "Created a chunk of size 1017, which is longer than the specified 600\n",
      "Created a chunk of size 740, which is longer than the specified 600\n",
      "Created a chunk of size 643, which is longer than the specified 600\n",
      "Created a chunk of size 828, which is longer than the specified 600\n",
      "Created a chunk of size 977, which is longer than the specified 600\n",
      "Created a chunk of size 603, which is longer than the specified 600\n",
      "Created a chunk of size 664, which is longer than the specified 600\n",
      "Created a chunk of size 685, which is longer than the specified 600\n",
      "Created a chunk of size 667, which is longer than the specified 600\n",
      "Created a chunk of size 849, which is longer than the specified 600\n",
      "Created a chunk of size 1179, which is longer than the specified 600\n",
      "Created a chunk of size 655, which is longer than the specified 600\n",
      "Created a chunk of size 693, which is longer than the specified 600\n",
      "Created a chunk of size 749, which is longer than the specified 600\n",
      "Created a chunk of size 721, which is longer than the specified 600\n",
      "Created a chunk of size 737, which is longer than the specified 600\n",
      "Created a chunk of size 637, which is longer than the specified 600\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/practice/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = loader = CSVLoader(\"../../data/rallit_text.csv\", encoding='utf8')\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a helpful assistant. \n",
    "            Answer the question based on the context below. You recommend a user's job.\n",
    "\n",
    "            1. Determines the similarity of your resume to a saved resume file based on your resume. \n",
    "            2. It recommends 3 jobs based on the similarity. \n",
    "            3. It includes the percentage of similarity for each recommended job.\n",
    "            4. The order of the job recommendations is provided in the order of the highest similarity. \n",
    "\n",
    "            \\n\\n\n",
    "            {context}\",\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"기술스택은 python, sql, java, kubernates이고, 프로젝트는 학교웹사이트를 개발한 적이 있습니다. 데이터베이스 구축과 백엔드 개발을 담당했습니다. 추천 직업을 알려주세요.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
